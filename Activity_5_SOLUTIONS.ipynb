{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c74206c0",
   "metadata": {},
   "source": [
    "# Activity 5: Minimization Problems and Least Squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "188d95c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import linalg as LA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cac7f3f",
   "metadata": {},
   "source": [
    "## Exercise 1: Some Utility Functions\n",
    "### Positive Definite Matrices\n",
    "Recall that a symmetric $n\\times n$ matrix $K$ is positive semi-definite if $\\vec x^T K \\vec x\\geq 0$ for all $\\vec x\\in \\mathbb R ^ n$, and positive definite if $\\vec x^T K \\vec x> 0$ for all $\\vec 0 \\neq\\vec x\\in \\mathbb R ^ n$.\n",
    "A very helpful characterization of positive definite matrices comes from the following theorem in Olver-Shakiban:\n",
    "\n",
    "**Theorem 3.43.** A symmetric matrix is positive definite if and only if it is regular and has all positive pivots.\n",
    "\n",
    "**Exercise: (a)** Below, give a function `is_pos_def` which determines if a matrix `A` is positive definite. We'll do this by checking that:\n",
    "- `A` is symmetric.\n",
    "- `A` is regular\n",
    "- `A` has all positive pivots\n",
    "Two of these properties are relatively unstable, so we will work up to a specified tolerance, set by default to (say) `10**(-10)`. That is, we'll say `A` is symmetric up to `tolerance` if `abs(A[i,j]-A[j,i])<tolerance`, and that it has positive pivots if each pivot is greater than the supplied tolerance.\n",
    "\n",
    "\n",
    "<details>\n",
    "    <summary> \n",
    "        <b> Hint:</b> (click to expand)\n",
    "    </summary>\n",
    "\n",
    "    A few built-in functions may be helpful\n",
    "    - `np.any` takes an array of booleans as input and returns `True` if at least one entry is `True`\n",
    "    - `np.any` takes an array of booleans as input and returns `True` if every entry is `True`\n",
    "    - `np.array_equal` checks if two arrays are equal on the nose.\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98dfaa45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perm_matrix(n,i,j):\n",
    "    E=np.identity(n)\n",
    "    E[[i,j]]=E[[j,i]]\n",
    "    return E\n",
    "def elem_matrix(n,i,j,a):\n",
    "    #constructs the elementary nxn matrix with value a in entry (i,j)\n",
    "    E=np.identity(n)\n",
    "    E[i][j]=a\n",
    "    return E\n",
    "def swapper(P,L,U,i,k): #OPTIONAL (if you wish to follow the outline)\n",
    "    n=P.shape[0]\n",
    "    perm=perm_matrix(n,i,k)\n",
    "    P=np.dot(perm,P)\n",
    "    U=np.dot(perm,U)\n",
    "    L=np.dot(perm,L-np.identity(n))+np.identity(n)\n",
    "    return (P,L,U)\n",
    "def my_PLU(A):\n",
    "    n=A.shape[0] #get number of rows\n",
    "    U=A.copy() #initialize U\n",
    "    L=np.identity(n) #initialize L\n",
    "    P=np.identity(n) #initialize P\n",
    "    for i in range(n): #parameterize pivots\n",
    "        if U[i][i]==0:  #if zero where pivot expected\n",
    "            k=i+1       #initialize k\n",
    "            swapped=False #initialize swapped\n",
    "            while k<n and swapped == False:\n",
    "                if U[k][i] != 0:          #zero where pivot expected\n",
    "                    (P,L,U)=swapper(P,L,U,i,k)\n",
    "                    swapped=True          #terminate the while loop\n",
    "                else:\n",
    "                    k+=1\n",
    "                    if k==n:\n",
    "                        raise Exception(\"singular matrix\") #this is optional, but might as well make it a bit more input-safe\n",
    "        for k in range(i+1,n):  # we may now safely assume U[i][i]=0\n",
    "            c=U[k][i] / U[i][i]   #compute which multiple of U[i] we'll need to subtract \n",
    "            U[k]=U[k] - c * U[i]  #clear out U[k][i]\n",
    "            L=np.dot(L, elem_matrix(n,k,i,c)) #Right-multiply L by the appropriate elementary matrix\n",
    "    return (P,L,U)\n",
    "def is_pos_def(A,tolerance=10**(-10)):\n",
    "    n=A.shape[0]\n",
    "    sym_table= np.array([[abs(A[i,j]-A[j,i])<tolerance for i in range(n)] for j in range(n)]) #matrix of booleans telling us if A fails to be symmetric\n",
    "    sym=np.all(sym_table)\n",
    "    (P,L,U)=my_PLU(A)\n",
    "    reg=(np.array_equal(P,np.identity(n))) #check P is trivial--if you implemented any pivoting, this might present an issue\n",
    "    pos_piv_table=np.array([U[i,i]>tolerance for i in range(n)])\n",
    "    pos_piv=np.all(pos_piv_table)\n",
    "    return sym and reg and pos_piv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "840578dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 30.,  60.,  10.],\n",
       "        [ 60., 126.,  16.],\n",
       "        [ 10.,  16.,  30.]]),\n",
       " True,\n",
       " array([[18., 20., 30., 28.],\n",
       "        [20., 33., 30., 51.],\n",
       "        [30., 30., 54., 42.],\n",
       "        [28., 51., 42., 81.]]),\n",
       " False)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#testing\n",
    "B=np.array([[1,2,3,4],[4,5,6,7],[-1,2,-3,4]],\"float64\")\n",
    "K1=np.dot(B,np.transpose(B))\n",
    "K2=np.dot(np.transpose(B),B)\n",
    "K1, is_pos_def(K1),K2,is_pos_def(K2)\n",
    "#What should be the correct output? Note rank(B)=3..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42f10945-7c7d-497f-ad48-60d3f00816fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.002525,  0.002475,  0.002525, -0.002475],\n",
       "        [ 0.002475,  0.002525,  0.002475, -0.002525],\n",
       "        [ 0.002525,  0.002475,  0.002525, -0.002475],\n",
       "        [-0.002475, -0.002525, -0.002475,  0.002525]]),\n",
       " False,\n",
       " True)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Testing pt 2\n",
    "L=np.array([[1,1,1,1.],\n",
    "[1,-1,1.,-1],\n",
    "[1,1,-1.,-1],\n",
    "[-1,1,1.,-1]],\"float64\")/2\n",
    "D=np.diag([10**-2,10**-4,10**-10,10**-12])\n",
    "K3= np.dot(L,np.dot(D,np.transpose(L)))\n",
    "K3,is_pos_def(K3),is_pos_def(K3,10**-13)\n",
    "# desired output: \n",
    "#(array([[ 0.002525,  0.002475,  0.002525, -0.002475],\n",
    "#        [ 0.002475,  0.002525,  0.002475, -0.002525],\n",
    "#        [ 0.002525,  0.002475,  0.002525, -0.002475],\n",
    "#        [-0.002475, -0.002525, -0.002475,  0.002525]]),\n",
    "# False,\n",
    "# True)\n",
    "# why does this make sense?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31dfecdb",
   "metadata": {},
   "source": [
    "### Minimization Problems\n",
    "In section 5.2 of Olver-Shakiban, we learned a systematic approach for minimizing quadratic functions.\n",
    "These are functions of the form $p(\\vec x) = \\vec x^T K \\vec x -2\\vec x^T \\vec f +c$, where $K$ is a symmetric $n\\times n$ matrix.\n",
    "Another theorem gives the minimizer and minimum:\n",
    "\n",
    "**Theorem 5.2.** If $K$ is a positive definite (and hence symmetric) matrix, then the quadratic function above has a unique minimizer, namely the solution $\\vec x^*$ to the linear system $K \\vec x =\\vec f$. The minimum value $p(\\vec x^*)$ is equal to $c-\\vec f ^t \\vec x^*$.\n",
    "\n",
    "**(b)** Below, give a function which returns the minimizer and minimum of the quadratic function represented by the triple `K,f,c`.\n",
    "Use a solving function from a previous activity to solve any linear systems (and not a built-in function).\n",
    "Your function should `raise` an `Exception` if the supplied matrix fails to be positive definite (this will end up being important later)\n",
    "\n",
    "**(c)** Use this to solve exercise 5.2.1: Find the global minimum value and global minimizer of the function $f(x,y,z)=x^2+2xy+3y^2+2yz+z^2-2x+3z+2$. Remember that any new arrays that you instantiate should be `\"float64\"` arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18faced1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_sub(L,b): #input: lower-triangular matrix L, vector of compatible dimension b. \n",
    "    n=b.shape[0]\n",
    "    c=np.zeros(n) #initialize output c\n",
    "    for i in range(n):\n",
    "        c[i]=(b[i]-sum([L[i][j]*c[j] for j in range(i)]))/L[i][i] #forward-substitution formula\n",
    "    return c\n",
    "def back_sub(U,c): #input: upper-triangular matrix L, vector of compatible dimension b. \n",
    "    n=c.shape[0]\n",
    "    x=np.zeros(n) #initialize output x\n",
    "    for i in range(n):\n",
    "        x[-(1+i)]=(c[-(1+i)]-sum([U[-(i+1)][-(j+1)]*x[-(j+1)] for j in range(i)]))/U[-(i+1)][-(i+1)] #back-substitution formula.\n",
    "    return x \n",
    "def my_solver(A,b):\n",
    "    (P,L,U)=my_PLU(A)\n",
    "    Pb=np.dot(P,b)\n",
    "    c=forward_sub(L,Pb)\n",
    "    x=back_sub(U,c)\n",
    "    return x\n",
    "def quadratic_min(K,f,c):\n",
    "    if not is_pos_def(K):\n",
    "        raise Exception(\"K fails to be positive definite\")\n",
    "    x_min=my_solver(K,f)\n",
    "    p_min=c-np.dot(f,x_min)\n",
    "    return (x_min,p_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e46b16b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 2., -3.,  2.]), -11.0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Testing\n",
    "K=np.array([\n",
    "    [1,1,1/2],\n",
    "    [1,2,1/2],\n",
    "    [1/2,1/2,2]\n",
    "],\"float64\")\n",
    "f=np.array([0,-3,7/2],\"float64\")\n",
    "c=5\n",
    "quadratic_min(K,f,c)\n",
    "#desired output (array([ 2., -3.,  2.]), -11.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "161f34b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-1., -1.,  4.]), -12.0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#part (c)\n",
    "K=np.array([[1,1,0],[1,3,1],[0,1,1]],\"float64\")\n",
    "f= np.array([-2,0,3],\"float64\")\n",
    "c=2\n",
    "quadratic_min(K,f,c)\n",
    "#Answer: -12.0 at (-1,-1,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cfd626f",
   "metadata": {},
   "source": [
    "## Exercise 2: Closest Point & Least Squares\n",
    "### Closest Point\n",
    "In the closest point problem, we are given a subspace $W\\subset \\mathbb{R}^m$ (typically with a basis given, say $\\vec w_1,\\dots \\vec w_n$) and a vector $\\vec b$ and asked to find the vector $\\vec w \\in W$ such that the distance $\\left \\lVert\\vec w-\\vec b \\right \\rVert$ is minimized.\n",
    "\n",
    "Since minimizing the square of a positive quantity is equivalent to minimizing the quantity itself, this is equivalent to minimizing $\\left \\lVert\\vec w-\\vec b \\right \\rVert^2=\\left \\langle \\vec w-\\vec b,\\vec w-\\vec b\\right \\rangle=\\left\\langle \\vec w,\\vec w\\right \\rangle -2\\left\\langle \\vec w,\\vec b\\right \\rangle+\\left \\lVert \\vec b\\right \\rVert^2$.\n",
    "Writing $\\vec w= x_1\\vec w_1 +\\dots +x_n\\vec w_n$ then gives the expression $\\left \\lVert \\vec w \\right \\rVert^2= \\sum_{i,j=1}^n k_{ij}x_ix_j=\\vec x^T K \\vec x$ where $K=(k_{ij})$ is the Gram matrix of the basis $\\vec w_1,\\dots, \\vec w_n$.\n",
    "We also note that the same trick of writing out $\\vec w$ in terms of the $\\vec w_i$ yields an expression $\\langle \\vec w, \\vec b \\rangle=\\sum x_i \\langle \\vec w_i, \\vec b\\rangle=\\vec x^T \\vec f$ where $f_i=\\langle \\vec w_i, \\vec b\\rangle$. In other words, we've expressed $\\left \\lVert\\vec w-\\vec b \\right \\rVert^2$ as the quadratic function $p(\\vec x) = \\vec x^T K \\vec x -2\\vec x^T \\vec f +c$ where $K$ and $\\vec f$ are given above and $c=\\left \\lVert \\vec b \\right \\rVert^2$. \n",
    "The minimizer $\\vec x^*$ to $p$ then gives the coefficients $x_1,\\dots,x_n$ for the closest point $\\vec w^*=x_1 \\vec w_1+\\dots +x_n \\vec w_n$.\n",
    "\n",
    "**Exercise (a):** Write a function which takes as input a matrix `W` whose columns are the vectors $\\vec w_1,\\dots \\vec w_n$ and a vector `b` and returns the closest point $\\vec w^*$ and its distance $\\left \\lVert \\vec w^* -\\vec b \\right \\rVert$. \n",
    "Do so by computing the appropriate objects `K`, `f` and `c`, passing those to `quadratic_min`, and transforming the output into appropriate form (for part of that, note that `np.sqrt` might be helpful).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0557de6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Gram(A): #this is a common enough need that we might as well make it its own function\n",
    "    return np.dot(np.transpose(A),A)\n",
    "def closest_point(W,b):\n",
    "    K=Gram(W)\n",
    "    f=np.dot(b,W)\n",
    "    c=np.dot(b,b)\n",
    "    (x_min,d_squared)=quadratic_min(K,f,c)\n",
    "    w_min=np.dot(W,x_min)\n",
    "    return w_min,np.sqrt(d_squared)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a60c12e3-e32b-43f9-bd99-27213b42be4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.66666667, -0.06666667, -0.46666667]), 0.5773502691896257)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Testing\n",
    "W=np.transpose(np.array([\n",
    "    [1,2,-1],\n",
    "    [2,-3,-1]\n",
    "    ],\"float64\"))\n",
    "b=np.array([1,0,0],\"float64\")\n",
    "closest_point(W,b)\n",
    "#desired output:\n",
    "#(array([ 0.66666667, -0.06666667, -0.46666667]), 0.5773502691896257)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "529ed1bb-a154-424b-9691-3657706e3401",
   "metadata": {},
   "source": [
    "### Least Squares\n",
    "The least squares problem for the system $A\\vec x=\\vec b$ is that of finding the $\\vec x^*$ which minimizes the difference between the two sides. \n",
    "Olver-Shakiban gives a theorem which computes $\\vec x^*$ directly:\n",
    "\n",
    "**Theorem 5.11.** Assume $\\ker A = \\{\\vec 0 \\}$. Then, the least squares solution to $A\\vec x = \\vec b$ under the Euclidean norm is $\\vec x^*$, the unique solution to the *normal equations*: $(A^T A) \\vec x = A^T \\vec b$.\n",
    "The *least squares error* is $\\left \\lVert A \\vec x^* - \\vec b\\right \\rVert^2$.\n",
    "\n",
    "**Exercise (b):** Modify your function from part (a) to give a function `least_squares` which provides the (more general) least squares solution and least squares error for a given matrix `A` and vector `b`. \n",
    "\n",
    "*Hint:* This should be a matter more-or-less of *removing* code from the previous function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2369b8df-bb19-4001-8000-49e591aae63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def least_squares(A,b):\n",
    "    K=Gram(A)\n",
    "    f=np.dot(b,A)\n",
    "    c=np.dot(b,b)\n",
    "    (x_min,d_min)=quadratic_min(K,f,c)\n",
    "    return x_min,d_min\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "14e9522b-a8a0-42f3-ae5e-08ccf3cd0a90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.4118705 ,  0.24820144, -0.95323741]), 0.0323741007194247)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Testing:\n",
    "A=np.array([\n",
    "    [1,2,0],\n",
    "    [3,-1,1],\n",
    "    [-1,2,1],\n",
    "    [1,-1,-2],\n",
    "    [2,1,-1]\n",
    "    ],\"float64\")\n",
    "b=np.array([1,0,-1,2,2],\"float64\")\n",
    "least_squares(A,b)\n",
    "#Desired Output: (array([ 0.4118705 ,  0.24820144, -0.95323741]), 0.0323741007194247)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b479034-b4fa-4b7e-ac0b-6b44fad95307",
   "metadata": {},
   "source": [
    "## Exercise 3: Data-fitting\n",
    "Read through the beginning of section 5.5 on Data Fitting and Interpolation on pages 254-258 of Olver-Shakiban.\n",
    "\n",
    "**Exercise: (a)** Write a function `linear_fit` which takes as input two vectors `t` and `y`. Use `least_squares` to compute $\\alpha,\\beta$ and print \"Line of best fit is y=$\\alpha$+$\\beta$t\", then return $(\\alpha,\\beta)$. \n",
    "\n",
    "(So for instance, if you find $\\alpha=3.1415$ and $\\beta=2.7183$, your function should print \"Line of best fit is y= 3.1415 + 2.7183 t\").\n",
    "\n",
    "Then, use `linear_fit` to solve problem 5.5.3(b) in Olver-Shakiban (estimating the price of a home in 2005 and 2010). You may [optionally] want to do this by writing another function that wraps `linear_fit` by taking an additional parameter $t_0$ (or parameters) and returning the predicted value $y(t_0)$ in service of your answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0a20a1a9-ffe6-4462-98ba-31b3da87e9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_fit(t,y):\n",
    "    A=np.array([[1., ti] for ti in t])\n",
    "    v=least_squares(A,y)[0]\n",
    "    print(\"line of best fit is y=\",v[0],\" + \",v[1],\"t\")  \n",
    "    return (v[0],v[1])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8ed49d0c-a74a-4755-a297-77cb87d6c7bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "line of best fit is y= 2.1428571428571432  +  1.6428571428571428 t\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2.1428571428571432, 1.6428571428571428)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Testing\n",
    "t=np.array([0,1,3,6.])\n",
    "y=np.array([2,4,7,12.])\n",
    "linear_fit(t,y)\n",
    "#desired output:\n",
    "#line of best fit is y= 2.1428571428571432  +  1.6428571428571428 t\n",
    "#(2.1428571428571432, 1.6428571428571428)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0ec763eb-832a-4825-a709-d1b7c78c2614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "line of best fit is y= -7717.709090917531  +  3.922727272731506 t\n",
      "line of best fit is y= -7717.709090917531  +  3.922727272731506 t\n",
      "147.3590909091381 166.97272727279596\n",
      "line of best fit is y= -7717.709090917531  +  3.922727272731506 t\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(2005, 147.3590909091381), (2010, 166.97272727279596)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Problem 5.5.3\n",
    "# year:   1989   1990   1991   1992   1993   1994   1995   1996   1997   1998   1999\n",
    "# amount: 86.4   89.8   92.8   96.0   99.6   103.1  106.3  109.5  113.3  120.0  129.5\n",
    "#optional helper function:\n",
    "def linear_predict(t,y,t_0):\n",
    "    a,b=linear_fit(t,y)\n",
    "    return a +b*t_0\n",
    "#(or even)\n",
    "def linear_predict2(t,y,*t_m):\n",
    "    a,b=linear_fit(t,y)\n",
    "    return [(t_0,a +b*t_0) for t_0 in t_m]\n",
    "t=np.array([1989,1990,1991,1992,1993,1994,1995,1996,1997,1998,1999],\"float64\")\n",
    "y=np.array([86.4,89.8,92.8,96.0,99.6,103.1,106.3,109.5,113.3,120.0,129.5],\"float64\")\n",
    "\n",
    "p_2005=linear_predict(t,y,2005)\n",
    "p_2010=linear_predict(t,y,2010)\n",
    "print(p_2005,p_2010)\n",
    "\n",
    "#or\n",
    "linear_predict2(t,y,2005,2010)\n",
    "\n",
    "#answer is: in 2005, 147.3590909091381; in 2010, 166.97272727279596"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92dea6be-ee9d-411e-b85d-45e9c25d8bb7",
   "metadata": {},
   "source": [
    "**(b):**\n",
    "Now, read the second portion of section 5.5 on pages 259-260 through theorem 5.60.\n",
    "Write a function `poly_fit` which implements the process for finding a line of best polynomial fit for a set of $t$-values `t` and a set of $y$-values `y`.\n",
    "Your function should take as an additional input an integer `n` and a parameter `t_0`.\n",
    "Return the result of inputting `t_0` to the polynomial giving the degree-`n` line of best fit.\n",
    "Do this using least squares by implementing the Vandermonde matrix presented in the text (probably as its own function).\n",
    "\n",
    "*Challenge (optional):* include a line which prints the formula for the line of best fit in human-readable form. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9444163f-b199-4043-a73e-08af351428b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def general_vandermonde(n,t=[]):\n",
    "    m=len(t)\n",
    "    return np.array([[t_i**j for j in range(n+1)] for t_i in t],\"float64\")\n",
    "def poly_string(x):\n",
    "    poly=\"line of best fit is \"\n",
    "    deg=0-6.615226941131597\n",
    "    for a in x:\n",
    "        poly=poly+\"(\"+str(a)+\")*t^\"+str(deg)+\" +\"\n",
    "        deg+=1\n",
    "    poly=poly[:-1]\n",
    "    return poly\n",
    "def poly_fit(n,t,y,t_0):\n",
    "    A=general_vandermonde(n,t)\n",
    "    x=least_squares(A,y)[0]\n",
    "    print(poly_string(x))\n",
    "    deg =0\n",
    "    tot=0\n",
    "    for a in x:\n",
    "        tot=tot+a * t_0**deg\n",
    "        deg+=1\n",
    "    return tot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b01bfe77-b8a9-4439-abf6-47b5208d4347",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "line of best fit is (3.0)*t^-6.615226941131597 +(-4.0)*t^-5.615226941131597 +(1.0)*t^-4.615226941131597 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-0.75"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#testing\n",
    "t=np.array([1,2,3,4],\"float64\")\n",
    "y=np.array([-1,2,-3,4],\"float64\")\n",
    "poly_fit(2,t,y,2.5)\n",
    "# desired output:\n",
    "# -0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1b65a3d9-f63c-46c2-960f-4b70a3339b2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "line of best fit is (0.125325100672444)*t^-6.615226941131597 +(-0.034181836967189)*t^-5.615226941131597 +(4.1904007237925995e-05)*t^-4.615226941131597 +(-3.848707678130196e-09)*t^-3.6152269411315974 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-6.615226941131597"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#testing part 2\n",
    "#testing\n",
    "t=np.array([1,10,10**2,10**3,10**4],\"float64\")\n",
    "y=np.array([-1,1,-3,4,0],\"float64\")\n",
    "poly_fit(3,t,y,10**(2.5))\n",
    "# desired output:\n",
    "# -6.615226941131597"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aadd890-3a27-4018-bf12-f9aedd3471e9",
   "metadata": {},
   "source": [
    "**(c):** Try the example below. What happens and why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ddbcb302-6c7f-42be-a9bd-c8a272e939e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing\n",
    "t=np.array([1,2,3,4],\"float64\")\n",
    "y=np.array([-1,2,-3,4],\"float64\")\n",
    "#poly_fit(4,t,y,np.sqrt(2))#UNCOMMENT ME!!!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "786e29b6-677c-4f1a-8c40-5ae4a27605f7",
   "metadata": {},
   "source": [
    "**Exercise:** Correct this issue. Give a function `poly_fit_safe` which has the same behavior except avoiding this pitfall. Your function should always return an approximation of the greatest reasonable degree less than or equal to `n`.\n",
    "\n",
    "<details>\n",
    "    <summary>\n",
    "        <b> Hint:</b> (Click here to open)\n",
    "    </summary>\n",
    "    \n",
    "- The issue is that there are *many* possible lines of best fit when we ask for one of too high degree. Correct this issue by simply changing the degree to the greatest reasonable choice when that happens.\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fa18c9b8-a3be-46db-9759-8c5f04a47cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def poly_fit_safe(n,t,y,t_0):\n",
    "    n_max=t.shape[0]-1\n",
    "    if n>n_max:\n",
    "        m=n_max\n",
    "        print(\"input degree too high, defaulting to n=\", m)\n",
    "    else:\n",
    "        m=n\n",
    "    A=general_vandermonde(m,t)\n",
    "    x=least_squares(A,y)[0]\n",
    "    print(poly_string(x))\n",
    "    deg =0\n",
    "    tot=0\n",
    "    for a in x:\n",
    "        tot=tot+a * t_0**deg\n",
    "        deg+=1\n",
    "    return tot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "942885bb-8945-4b0d-875e-dc26c975be60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input degree too high, defaulting to n= 3\n",
      "line of best fit is (-32.000000000005315)*t^-6.615226941131597 +(51.6666666666751)*t^-5.615226941131597 +(-24.000000000003787)*t^-4.615226941131597 +(3.3333333333338384)*t^-3.6152269411315974 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.495791138430997"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#testing\n",
    "t=np.array([1,2,3,4],\"float64\")\n",
    "y=np.array([-1,2,-3,4],\"float64\")\n",
    "poly_fit_safe(4,t,y,np.sqrt(2))\n",
    "#desired output: 2.495791138430997"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1225d4-dfbc-429a-8c10-c75afa86d3d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
